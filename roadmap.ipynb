{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project roadmap and code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Questions](#1\\.-Questions)\n",
    "2. [Schedule](#2\\.-Schedule)\n",
    "3. [Documentation and first hands-on](#3\\.-Documentation-and-first-hands-on)\n",
    "4. [Data generation](#4\\.-Data-generation)\n",
    "5. [Data processing](#5\\.-Data-processing)\n",
    "6. [Machine learning](#6\\.-Machine-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Questions\n",
    "\n",
    "Questions I wonder are grouped here:\n",
    "\n",
    "- *In IGV usage*: **Question:** I'm not sure how to understand the vcf file in IGV, how do I know if it's an insertion or a deletion? Do the files I loaded correspond to one another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schedule\n",
    "\n",
    "### Week 1\n",
    "- Meeting and get in touch with colleagues and Rick's work ✔️\n",
    "- Download data and visualize with IGV ✔️\n",
    "- Get in touch with formats (vcf, bam, ...) ✔️\n",
    "- Read gnomAD paper ✔️\n",
    "\n",
    "### Week 2\n",
    "- Look at how they extract their features in the papers\n",
    "- Extract data with Canevas from one genome of Genome in a Bottle\n",
    "- Load data and pre-process it if needed\n",
    "- Split train test (deletions -> split randomly in train/test)\n",
    "- Compare our features to theirs\n",
    "- Start running model if time\n",
    "\n",
    "### Week 3\n",
    "- Process data in python (train, test)\n",
    "- Start constructing models, using multiple filters as inputs and VCF as output\n",
    "    - Random forest for feature importance? to rank filters\n",
    "    - Deep learning?\n",
    "    - Adaboost?\n",
    "\n",
    "### Week 4\n",
    "- Continue machine learning models\n",
    "- Validate, compute performance\n",
    "\n",
    "### Week 5\n",
    "To be determined... (if work left, enough time, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Documentation and first hands-on\n",
    "\n",
    "This section will contain the steps done towards documentation, data exploration, IGV usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IGV usage\n",
    "\n",
    "First, I downloaded [IGV 2.8.3](http://software.broadinstitute.org/software/igv/download) for Linux\n",
    "\n",
    "Then I downloaded this data [here](ftp://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/NA12878_PacBio_MtSinai/) from [Genome in a Bottle](https://www.nist.gov/programs-projects/genome-bottle):\n",
    "- `NA12878.sorted.vcf.gz`\n",
    "- `NA12878.sorted.vcf.gz.tbi`\n",
    "- `README.txt`\n",
    "- `merged_ec_output_primary.bam`\n",
    "- `merged_ec_output_primary.bam.bai`\n",
    "\n",
    "I tried to load `NA12878.sorted.vcf.gz` and `merged_ec_output_primary.bam` in IGV but there was a parsing error in the vcf file:\n",
    "- I realized line 4 `#contig=<ID=chr1,...` was missing a `#` at the begginning\n",
    "- I had to change the spaces in the header line to `\\t`\n",
    "\n",
    "I then was able to load the two files in IGV and have a visualization:\n",
    "\n",
    "**Question:** I'm not sure how to understand the vcf file in IGV, how do I know if it's an insertion or a deletion? Do the files I loaded correspond to one another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IGV image](images/igv-NA12878-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data generation\n",
    "\n",
    "This section will contain the steps done towards data creation with [Canevas](https://github.com/rick-heig/canevas), different filters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data processing\n",
    "\n",
    "This section will contain the steps done towards data processing in order to use it in the machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
